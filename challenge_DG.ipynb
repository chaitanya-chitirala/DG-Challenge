{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-5gUFJLMKNNb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 and Q2: Generating Fake Images with an efficient data structure\n",
        "\n",
        "In Python to create an array, we either use a Python list, NumPy array or a tensor. I am using a NumPy array to represent the images.\n",
        "\n",
        "However, this would be computationally expensive if it's a high resolution 100,000*100,000 image. We have to use encoding/compression techniques to reduce the size of the image.\n",
        "\n",
        "My idea in the code below, is that of an image which is one-hot encoded(with boolean values). As we are dealing with images which are binary in nature (parasite cells/not parasite cells and cancer cells/not cancer cells), we can represent the image with 1's and 0's replacing each pixel value(rather than the intensity values which are the traditional way of an image being represented).\n",
        "\n",
        "\n",
        "Furthermore, we could use coding technqiues such as Huffman coding for lossless data compression(commonly used in JPEG), to further downsize the image.\n",
        "\n",
        "I am using a torch.rand function to generate random numbers from 0 to 1. Since we expect the parasitic cells to occupy atleast 25% of the image, I am converting the random tensor array to a boolean by using 0.25 as a lower bound.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xl739bhc8TjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to generate an image(post processed)\n",
        "\n",
        "def gen_image(rows,cols):\n",
        "  #parasite1 = torch.HalfTensor(rows,cols).uniform_()>0.25\n",
        "  #dye_image = torch.HalfTensor(rows,cols).uniform_()>.901\n",
        "  parasite1 = torch.rand(rows, cols)>0.25\n",
        "  dye_image = torch.rand(rows, cols)>0.901\n",
        "  dye_image = np.array(dye_image)\n",
        "  parasite1 = np.array(parasite1)\n",
        "\n",
        "  return parasite1, dye_image\n",
        "  "
      ],
      "metadata": {
        "id": "xT2GCnA8KXNt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the worst case storage size scenario. For a 512*512 image with all 1's(all pixels corresponds to parasite cells). The size would be 262,264 bytes or (262 KB)"
      ],
      "metadata": {
        "id": "30ZMXwv8BxnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#worst case storage scenario in bytes\n",
        "\n",
        "sys.getsizeof(np.array(torch.rand(512,512)>0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNvi7ANIOvIQ",
        "outputId": "23235efa-ccdd-4d4e-b6fb-999aacb8164a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "262264"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 and Q3) In the code below, I am generating 1000 images of size 512*512 (1000 parasite images and 1000 dye tested parastie images). I am using the location of the parasitic cells as a contour to extract only the pixels within the boundary ( as we are not bothered with the dye lit pixels outside the parasite's body).\n",
        "\n",
        "Then, I am calculating the ratio of cancer cells to the total area of the parasite's body for each image."
      ],
      "metadata": {
        "id": "l6r_hHB4Pgc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 512\n",
        "cols = 512\n",
        "ratio = []\n",
        "\n",
        "for i in range(1000):\n",
        "  parasite_count = []\n",
        "  dye_ROI_count = []\n",
        "  Coordinates = []\n",
        "  \n",
        "  \n",
        "  parasite_img, dye_img = gen_image(rows, cols)\n",
        "  parasite_pos = np.where(parasite_img == True)\n",
        "  Coordinates= list(zip(parasite_pos[0], parasite_pos[1]))\n",
        "  positions = np.array(Coordinates)\n",
        "  for j in positions:\n",
        "    dye_ROI_count.append(dye_img[j[0],j[1]])\n",
        "  cancer_count = dye_ROI_count.count(True)\n",
        "  para_count = np.count_nonzero(parasite_img)\n",
        "  ratio.append(cancer_count/para_count)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "551ewOSpM97b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the ratio list to a numpy array"
      ],
      "metadata": {
        "id": "2iQV5ZRnNhlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ratio = np.array(ratio)"
      ],
      "metadata": {
        "id": "-8RJnpvDRiMV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3) Using a conditional operator, to convert the ratio array to a boolean(with 1's corresponding to the image pairs where the cancer cells occupied more than 10% of the parasite body)"
      ],
      "metadata": {
        "id": "Pj9KeLuUNles"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_ROI = ratio>0.1"
      ],
      "metadata": {
        "id": "Pcx1-AddRjzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.count_nonzero(ratio_ROI)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDS3u51PZiyj",
        "outputId": "7d63d09d-eae3-4ea2-a921-6645c883c564"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Based on the generated fake images. There are 82 images out of 1000 (8.2%) which corresponds to cancer cells occupying more than 10% of the image"
      ],
      "metadata": {
        "id": "KCBnnVkTN_gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Improvement***\n",
        "\n",
        "One improvement which I can do is\n",
        "a. Use compression techniques to compress the image further(using transforms such as wavelet transforms to compress without much loss and then use the functions later)\n",
        "\n",
        "b. Reading the Images through a pandas dataframe and using the utility of Pandas boolean masks and comparisions, I could make the code faster."
      ],
      "metadata": {
        "id": "8q-7DrOnRo0c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAuEi-dkQk73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}